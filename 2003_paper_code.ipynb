{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:5] #print first 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[x.lower() for x in words] #lowwrcasing all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and  mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(len(itos))  #so vocabulary length is 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length\n",
    "\n",
    "def build_dataset(words,st):  \n",
    "  X, Y = [], []\n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix]  # crop context and append next character\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print('{0} size is ---->   examples: {1} and targets is {2} '.format(st,X.shape, Y.shape))\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size is ---->   examples: torch.Size([44725, 3]) and targets is torch.Size([44725]) \n",
      "Validation size is ---->   examples: torch.Size([5599, 3]) and targets is torch.Size([5599]) \n",
      "Testing size is ---->   examples: torch.Size([5544, 3]) and targets is torch.Size([5544]) \n"
     ]
    }
   ],
   "source": [
    "#building train 80% ,validation 10% ,test data 10% splits\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1],'Training')\n",
    "Xdev, Ydev = build_dataset(words[n1:n2],'Validation')\n",
    "Xte, Yte = build_dataset(words[n2:],'Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtr=Xtr.float()\n",
    "# Ytr=Ytr.float()\n",
    "# Xdev=Xdev.float()\n",
    "# Ydev=Ydev.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init the neural net\n",
    "dim=10\n",
    "hidden=200\n",
    "gain=5/3\n",
    "C = torch.randn((len(itos), dim))  # 10 dimensional lookup table for vocabulary size.\n",
    "W1 = torch.randn((block_size*dim, hidden))* gain/((block_size*dim)**0.5) #3*10=30 (context * dim= size of one input)\n",
    "#b1 = torch.randn(hidden) * 0\n",
    "W2 = torch.randn((hidden, len(itos))) * 0.01\n",
    "b2 = torch.randn(len(itos)) * 0\n",
    "scale=torch.ones(1,hidden)*0.01\n",
    "shift=torch.zeros(1,hidden)*0.01\n",
    "parameters = [C, W1,scale,shift, W2, b2] #b1 not req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12730"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting requires_grad=True for all parameters\n",
    "for p in parameters:\n",
    "  p.requires_grad = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init parameters for training\n",
    "lossi = []\n",
    "stepi = []\n",
    "epochs=100000\n",
    "lr=0.01\n",
    "alpha=0.1\n",
    "batch_size=32\n",
    "first_mom=0\n",
    "second_mom=0\n",
    "first_mom=first_mom/(1-0.9*100)\n",
    "second_mom=second_mom/(1-0.999*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C[Xtr] === C @ one_hot of Xtr example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at 1 iteration is 2.5834903717041016\n",
      "loss at 5001 iteration is 2.1327292919158936\n",
      "loss at 10001 iteration is 2.0441415309906006\n",
      "loss at 15001 iteration is 1.8372997045516968\n",
      "loss at 20001 iteration is 2.0371363162994385\n",
      "loss at 25001 iteration is 2.100309371948242\n",
      "loss at 30001 iteration is 2.081117868423462\n",
      "loss at 35001 iteration is 2.198269844055176\n",
      "loss at 40001 iteration is 1.8516473770141602\n",
      "loss at 45001 iteration is 2.2413129806518555\n",
      "loss at 50001 iteration is 2.1094748973846436\n",
      "loss at 55001 iteration is 1.667232871055603\n",
      "loss at 60001 iteration is 2.1863088607788086\n",
      "loss at 65001 iteration is 2.4835562705993652\n",
      "loss at 70001 iteration is 1.7741042375564575\n",
      "loss at 75001 iteration is 1.740194320678711\n",
      "loss at 80001 iteration is 1.9886850118637085\n",
      "loss at 85001 iteration is 2.117891788482666\n",
      "loss at 90001 iteration is 1.8746719360351562\n",
      "loss at 95001 iteration is 2.1343894004821777\n",
      "loss at 100001 iteration is 2.233757972717285\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs+1):\n",
    "    #sample a batch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    \n",
    "    #forward pass\n",
    "    emb=C[Xtr] # projecting each character to 10 dim \n",
    "    normli1= C[Xtr[ix]].view(-1,block_size*dim) @ W1 #+ b1\n",
    "    \n",
    "    #batch normalization\n",
    "    normli= (normli1-normli1.mean(axis=0,keepdim=True))/normli1.std(axis=0,keepdim=True)\n",
    "    normli=normli*scale + shift\n",
    "    \n",
    "    \n",
    "    temp=torch.tanh(normli)\n",
    "    logits= temp @ W2 + b2\n",
    "    \n",
    "    #softmax\n",
    "    counts = logits.exp() \n",
    "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    \n",
    "    #negative log likelyhood loss loss fn\n",
    "    loss = -probs[torch.arange(len(Xtr[ix])), Ytr[ix]].log().mean() + alpha*(W1**2).mean()\n",
    " \n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad=None\n",
    "        \n",
    "    loss.backward()\n",
    "\n",
    "    #parameter update\n",
    "    for p in parameters:\n",
    "        lr=0.01 if i<10000 else 0.1 \n",
    "        p.data-=lr*p.grad\n",
    "        \n",
    "      #adam update\n",
    "#     for p in parameters:\n",
    "#         print(p.grad.shape)\n",
    "#         first_mom=0.9*first_mom+0.1*p.grad\n",
    "#         second_mom=0.999*second_mom+0.001*p.grad**2\n",
    "#         eff_lr=1/((second_mom**2+0.00001)**0.5)\n",
    "#         p.data-=eff_lr*first_mom\n",
    "\n",
    "    if(i%5000==0):\n",
    "        print('loss at {0} iteration is {1}'.format(i+1,loss.item()))\n",
    "    \n",
    "    \n",
    "    #for stats\n",
    "    stepi.append(i)\n",
    "    lossi.append(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting stpes vs loss\n",
    "plt.plot(stepi,lossi,'ro')\n",
    "plt.xlabel(\"iteration no\")\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for validation set is 2.2997658252716064\n"
     ]
    }
   ],
   "source": [
    "#loss for validation set\n",
    "#sample a batch\n",
    "ix = torch.randint(0, Xdev.shape[0], (batch_size,))\n",
    "\n",
    "#forward pass\n",
    "emb=C[Xdev] # projecting each character to 10 dim \n",
    "normli1= C[Xdev[ix]].view(-1,block_size*dim) @ W1 #+ b1\n",
    "\n",
    "#batch normalization\n",
    "normli= (normli1-normli1.mean(axis=0,keepdim=True))/normli1.std(axis=0,keepdim=True) #or calculate running and var with momentum.\n",
    "normli=normli*scale + shift\n",
    "\n",
    "\n",
    "temp=torch.tanh(normli)\n",
    "logits= temp @ W2 + b2\n",
    "\n",
    "#softmax\n",
    "counts = logits.exp() \n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "\n",
    "#negative log likelyhood loss loss fn\n",
    "loss_dev = -probs[torch.arange(len(Xdev[ix])), Ydev[ix]].log().mean() + alpha*(W1**2).mean()\n",
    "\n",
    "print('loss for validation set is {0}'.format(loss_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for test set is 2.0711169242858887\n"
     ]
    }
   ],
   "source": [
    "#loss for test set\n",
    "#sample a batch\n",
    "ix = torch.randint(0, Xte.shape[0], (batch_size,))\n",
    "\n",
    "#forward pass\n",
    "emb=C[Xte] # projecting each character to 10 dim \n",
    "normli1= C[Xte[ix]].view(-1,block_size*dim) @ W1 #+ b1\n",
    "\n",
    "#batch normalization\n",
    "normli= (normli1-normli1.mean(axis=0,keepdim=True))/normli1.std(axis=0,keepdim=True) #or calculate running and var with momentum.\n",
    "normli=normli*scale + shift\n",
    "\n",
    "\n",
    "temp=torch.tanh(normli)\n",
    "logits= temp @ W2 + b2\n",
    "\n",
    "#softmax\n",
    "counts = logits.exp() \n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "\n",
    "#negative log likelyhood loss loss fn\n",
    "loss_te = -probs[torch.arange(len(Xte[ix])), Yte[ix]].log().mean() + alpha*(W1**2).mean()\n",
    "\n",
    "print('loss for test set is {0}'.format(loss_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "josangel.\n",
      "dannteth.\n",
      "ufwudleva.\n",
      "darg.\n",
      "dorest.\n",
      "adgenusthpe.\n",
      "pannustia.\n",
      "dugta.\n",
      "strest.\n",
      "aggiddanne.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "for i in range(10):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,dim)\n",
    "      temp = (emb.view(1, -1) @ W1 )\n",
    "      temp=temp-temp.mean()/temp.std()\n",
    "      temp=temp*scale+shift\n",
    "      h=torch.tanh(temp)\n",
    "      logits = h @ W2 + b2\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples from the model\n",
    "# 1)normal implementatoin \n",
    "# felgrlnna.\n",
    "# mar.\n",
    "# tiph.\n",
    "# rey.\n",
    "# aatia.\n",
    "# ald.\n",
    "# tibe.\n",
    "# juspattan.\n",
    "# fzopseffiegane.\n",
    "# macy.\n",
    "\n",
    "# 2)normal implementaion + good init of network + batch normalization\n",
    "# agretti.\n",
    "# plarmeliannethioshe.\n",
    "# darconsoliquettts.\n",
    "# ddt.\n",
    "# jomatqe.\n",
    "# did.\n",
    "# panny.\n",
    "# digita.\n",
    "# lappengel.\n",
    "\n",
    "\n",
    "\n",
    "#3)normal implementaion + good init of network + batch normalization + adam optimizer\n",
    "#nerdre.\n",
    "#lerome.\n",
    "#sterrie.\n",
    "#neila.\n",
    "#martie.\n",
    "#and.\n",
    "#josette.\n",
    "#ciley.\n",
    "#romeo.\n",
    "#ira."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
